{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Also known as `L1 regularization`\n",
    "\n",
    "It's a regularization technique used in feature selection using ashrinkage method referred to as `penalized regression model`\n",
    "\n",
    "LASSO => Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "The primary goal of LASSO regression is to ind a balance between model simplicity and accuracy\n",
    "\n",
    "It's used over regression methods for a more accurate prediction\n",
    "\n",
    "It uses shrinkage, where data values are shrunk towards a central point as the mean\n",
    "\n",
    "It's well suited for models with high levels of multicollinearity\n",
    "\n",
    "It's also used to perform feature selection automatically\n",
    "\n",
    "## Steps of how LASSO regression works\n",
    "\n",
    "1. **Linear regression model**: LASSO regression starts with the standard linear regression model.\n",
    "\n",
    "2. **L1 regularization**: LASSO introduces an additional penalty term based on the absolute values of the coefficients\n",
    "    - L1 regularization term is the sum of the absolute values of the coefficients multiplied by a tuning parameter `λ` \n",
    "    > y = λ + (|β₁| + |β₂| + ... + |βm|)\n",
    "    - Where:\n",
    "        - λ is the regularization parameter\n",
    "        - B<sub>1</sub> ... B<sub>m</sub> are the coefficients\n",
    "\n",
    "3. **Objective function**: the objective of LASSO regression is to find values of the coefficients that minimize the Mean Squared Error while also minimizing the L1 regularization term\n",
    "    - minimize `RSS + L<sub>1</sub>`\n",
    "    - where\n",
    "        - RSS -  is the MSE\n",
    "        - L1 - regularization term\n",
    "\n",
    "4. **Shrinking Coefficients**: By adding `L1`, LASSO can shrink the coefficients towards 0\n",
    "    When λ is large enough, some coefficients are driven to exactly 0\n",
    "    - This property makes LASSO perform feature selection, as variables with 0 coefficients are removed from the model\n",
    "\n",
    "5. **Tuning Parameter**: λ affects the features selected by the model. This is because a increase in λ means an increase in the number of coefficients being 0 thus a decrease in the number of features selected and vice versa\n",
    "\n",
    "6. **Model Fitting**: an optimization algorithm should used to minimize the `objective function`\n",
    "\n",
    "## Regularization\n",
    "\n",
    "It's implemented by adding a penalty term to the best fit derived from the trained data\n",
    "\n",
    "It's a technique to prevent a model from overfitting by adding extra information to it\n",
    "\n",
    "It is achieved by keeping the number of features constant but reducing the magnitude of the coefficients\n",
    "\n",
    "### L1 Regularization\n",
    "\n",
    "if a regression model uses `L1 regularization` it's called `LASSO` regression\n",
    "\n",
    "L1 regularization adds a penalty that's equal to the absolute value of the magnitude of the coefficient\n",
    "\n",
    "\n",
    "## LASSO Regression Equation\n",
    "\n",
    "L<sub>lasso</sub> = Σ<sup>n<sup><sub>i= 1</sub> (y<sub>i</sub> - X'B^)<sup>2</sup> + λ Σ<sup>m</sup><sub>j=1</sub> | B^ |\n",
    "\n",
    "Where,\n",
    "    - λ is the penalty term\n",
    "\n",
    "when λ = 0 the model is simply a linear regression\n",
    "λ can be betweeen 0 - ∞"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
